{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82ae7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ce5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(seq, n):\n",
    "    \"\"\"Generate a list of n-grams from a sequence.\"\"\"\n",
    "    return [seq[i:i+n] for i in range(len(seq)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e31fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_common_sequence(seq1, seq2, max_n):\n",
    "    \"\"\"Find the longest common sequence of words between two sequences using n-grams.\"\"\"\n",
    "    words1 = seq1.split()\n",
    "    words2 = seq2.split()\n",
    "    n = max_n\n",
    "    while n > 0:\n",
    "        ngrams1 = generate_ngrams(words1, n)\n",
    "        ngrams2 = generate_ngrams(words2, n)\n",
    "        m = [[0] * (len(ngrams2)+1) for _ in range(len(ngrams1)+1)]\n",
    "        for i in range(1, len(ngrams1)+1):\n",
    "            for j in range(1, len(ngrams2)+1):\n",
    "                if ngrams1[i-1] == ngrams2[j-1]:\n",
    "                    m[i][j] = m[i-1][j-1] + 1\n",
    "                else:\n",
    "                    m[i][j] = max(m[i-1][j], m[i][j-1])\n",
    "        lcs_length = m[-1][-1]\n",
    "        if lcs_length > 0:\n",
    "            lcs = []\n",
    "            i, j = len(ngrams1), len(ngrams2)\n",
    "            while lcs_length > 0:\n",
    "                if ngrams1[i-1] == ngrams2[j-1]:\n",
    "                    lcs.append(ngrams1[i-1])\n",
    "                    i -= 1\n",
    "                    j -= 1\n",
    "                    lcs_length -= 1\n",
    "                elif m[i-1][j] > m[i][j-1]:\n",
    "                    i -= 1\n",
    "                else:\n",
    "                    j -= 1\n",
    "            lcs.reverse()\n",
    "            lcs_words = [lcs[0]]\n",
    "            for i in range(1, len(lcs)):\n",
    "                overlap = n - 1\n",
    "                while overlap >= 0:\n",
    "                    if lcs[i-1][n-overlap:] == lcs[i][:overlap]:\n",
    "                        break\n",
    "                    overlap -= 1\n",
    "                lcs_words.append(lcs[i][overlap:])\n",
    "            return lcs_words\n",
    "        n -= 1\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b27198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['घोडामा']]\n",
      "['घोडामा']\n"
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "lcs = find_longest_common_sequence(seq1, seq2, 4)\n",
    "print(lcs)\n",
    "lcs_words = [\" \".join(ngram) for ngram in lcs] \n",
    "text.append(\" \".join(lcs_words)) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca53a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = \"घोडामा सवार एकजना भाँचिएको हवाइजहाजमाथि हाम फाल्छन्।\"\n",
    "seq2 = \"एक व्यक्ति घोडामा बाहिर छ।\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d2a52",
   "metadata": {},
   "source": [
    "# //hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c331790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common bigram: ('फसलाई', 'दिइने') (Index in Paragraph 1: 10), (Index in Paragraph 2: 1)\n",
      "Common bigram: ('दिइने', 'भएको') (Index in Paragraph 1: 11), (Index in Paragraph 2: 2)\n",
      "Common bigram: ('यस', 'वर्षको') (Index in Paragraph 1: 2), (Index in Paragraph 2: 9)\n",
      "Common bigram: ('भएको', 'छ') (Index in Paragraph 1: 12), (Index in Paragraph 2: 3)\n",
      "Common bigram: ('वर्षको', 'नोबेल') (Index in Paragraph 1: 3), (Index in Paragraph 2: 10)\n",
      "Common bigram: ('योन', 'फसलाई') (Index in Paragraph 1: 9), (Index in Paragraph 2: 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk import bigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample paragraphs (replace with your text)\n",
    "paragraph1 = \"काठमाडौँ — यस वर्षको नोबेल साहित्य पुरस्कार नर्वेली लेखक योन फसलाई दिइने भएको छ \"\n",
    "paragraph2 = \"योन फसलाई दिइने भएको छ । बिहीबार रोयल स्विडिस यस वर्षको नोबेल साहित्\"\n",
    "\n",
    "# Tokenize the paragraphs into words\n",
    "words1 = word_tokenize(paragraph1)\n",
    "words2 = word_tokenize(paragraph2)\n",
    "\n",
    "# Create bigrams from the tokenized words\n",
    "bigrams1 = list(bigrams(words1))\n",
    "bigrams2 = list(bigrams(words2))\n",
    "\n",
    "# Find common bigrams\n",
    "common_bigrams = set(bigrams1) & set(bigrams2)\n",
    "\n",
    "# Get the index numbers of common bigrams in the original paragraphs\n",
    "common_bigram_indices = []\n",
    "for bigram in common_bigrams:\n",
    "    index1 = bigrams1.index(bigram)\n",
    "    index2 = bigrams2.index(bigram)\n",
    "    common_bigram_indices.append((index1, index2))\n",
    "\n",
    "# Print common bigrams and their index numbers\n",
    "for index1, index2 in common_bigram_indices:\n",
    "    print(f\"Common bigram: {bigrams1[index1]} (Index in Paragraph 1: {index1}), \"\n",
    "          f\"(Index in Paragraph 2: {index2})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815a0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
